{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52e3d801",
   "metadata": {},
   "source": [
    "# Phase 1: Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d92f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d69ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the MySQL database\n",
    "conn = pymysql.connect(\n",
    "    host='localhost',\n",
    "    user='your_mysql_username',\n",
    "    password='your_mysql_username',\n",
    "    database='book_store'\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f488fe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from CSV files\n",
    "authors_df = pd.read_csv('.csv adatforrások/authors.csv')\n",
    "book_genres_df = pd.read_csv('.csv adatforrások/book_genres.csv')\n",
    "books_df = pd.read_csv('.csv adatforrások/books.csv', usecols=['id','title','author_id','release_date',\n",
    "                                                               'description','list_price'], encoding=\"utf-8-sig\")\n",
    "customers_df = pd.read_csv('.csv adatforrások/customers.csv', encoding=\"utf-8-sig\")\n",
    "genres_df = pd.read_csv('.csv adatforrások/genres.csv')\n",
    "inventory_df = pd.read_csv('.csv adatforrások/inventory.csv')\n",
    "order_items_df = pd.read_csv('.csv adatforrások/order_items.csv')\n",
    "orders_df = pd.read_csv('.csv adatforrások/orders.csv')\n",
    "payments_df = pd.read_csv('.csv adatforrások/payments.csv')\n",
    "warehouses_df = pd.read_csv('.csv adatforrások/warehouses.csv', encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb011bf9",
   "metadata": {},
   "source": [
    "## What’s Happening Here?\n",
    "* We start by importing the necessary libraries: pandas for data manipulation and mysql.connector to connect to the MySQL database.\n",
    "* We then establish a connection to the MySQL database using the mysql.connector.connect method.\n",
    "* The pd.read_csv function is used to extract data from CSV files, respectively. This data is loaded into DataFrames, which are versatile and powerful data structures in Python that allow us to easily manipulate and analyze the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3327f583",
   "metadata": {},
   "source": [
    "# Phase 2: Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f98fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update list prices in order_items table\n",
    "for i in range(len(books_df)):\n",
    "    mask = order_items_df['book_id'] == books_df.loc[i, 'id']\n",
    "    order_items_df.loc[mask, 'unit_price'] = books_df.loc[i, 'list_price']\n",
    "\n",
    "# Calculate total amount in orders table\n",
    "for i in range(len(orders_df)):\n",
    "    total = 0\n",
    "    mask = order_items_df['order_id'] == orders_df.loc[i, 'id']\n",
    "    total = order_items_df.loc[mask, 'line_total'].sum()\n",
    "    orders_df.loc[i, 'total_amount'] = total\n",
    "\n",
    "# Calculate total stock in orders table\n",
    "for i in range(len(orders_df)):\n",
    "    total = 0\n",
    "    mask = order_items_df['order_id'] == orders_df.loc[i, 'id']\n",
    "    total = order_items_df.loc[mask, 'order_quantity'].sum()\n",
    "    orders_df.loc[i, 'total_stock'] = total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1500d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling invalid emails in the Users DataFrame\n",
    "def generate_unique_email(index):\n",
    "    return f'unknown_{index}@example.com'\n",
    "\n",
    "customers_df['emailaddress'] = customers_df.apply(lambda row: row['emailaddress'] if '@' in row['emailaddress'] and '.' in row['emailaddress'] else generate_unique_email(row.name), axis=1)\n",
    "\n",
    "# Ensure all prices are numeric\n",
    "books_df['list_price'] = pd.to_numeric(books_df['list_price'], errors='coerce').fillna(0.0).round(2)\n",
    "orders_df['total_amount'] = pd.to_numeric(orders_df['total_amount'], errors='coerce').fillna(0.0).round(2)\n",
    "order_items_df['unit_price'] = pd.to_numeric(order_items_df['unit_price'], errors='coerce').fillna(0.0).round(2)\n",
    "order_items_df['line_total'] = pd.to_numeric(order_items_df['line_total'], errors='coerce').fillna(0.0).round(2)\n",
    "\n",
    "# Ensure all stock quantities are numeric\n",
    "orders_df['total_stock'] = pd.to_numeric(orders_df['total_stock'], errors='coerce').fillna(0).astype(int)\n",
    "order_items_df['order_quantity'] = pd.to_numeric(order_items_df['order_quantity'], errors='coerce').fillna(0).astype(int)\n",
    "inventory_df['quantity'] = pd.to_numeric(inventory_df['quantity'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Standardize and convert date formats to string\n",
    "books_df['release_date'] = pd.to_datetime(books_df['release_date'], errors='coerce', format='%Y-%m-%d').fillna(pd.Timestamp('1971-01-01'))\n",
    "books_df['release_date'] = books_df['release_date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "orders_df['order_date'] = pd.to_datetime(orders_df['order_date'], errors='coerce').fillna(pd.Timestamp('1971-01-01'))\n",
    "orders_df['order_date'] = orders_df['order_date'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "orders_df['ship_date'] = pd.to_datetime(orders_df['ship_date'], errors='coerce').fillna(pd.Timestamp('1971-01-01'))\n",
    "orders_df['ship_date'] = orders_df['ship_date'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "customers_df['dateofbirth'] = pd.to_datetime(customers_df['dateofbirth'], errors='coerce', format='%Y-%m-%d').fillna(pd.Timestamp('1971-01-01'))\n",
    "customers_df['dateofbirth'] = customers_df['dateofbirth'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Replace negative values with 0 in inventory table\n",
    "inventory_df['quantity'] = inventory_df['quantity'].clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d197023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in customers dataframe as needed\n",
    "customers_df = customers_df.fillna({\n",
    "    'gender': 'Missing',\n",
    "    'dateofbirth': '1971-01-01',\n",
    "    'postalcode': 'Missing',\n",
    "    'country': 'Missing',\n",
    "    'region': 'Missing',\n",
    "    'city': 'Missing',\n",
    "    'street': 'Missing',\n",
    "    'houseno': 'Missing',\n",
    "    'registrationdate': '1971-01-01'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bde36f4",
   "metadata": {},
   "source": [
    "## What’s Happening Here?\n",
    "* Filling Missing Values: We use the fillna method to replace missing values with default values. For example, if the Description or Category fields are missing in the products_df DataFrame, we fill them with 'No description available' and 'Miscellaneous', respectively.\n",
    "* Handling Invalid Emails: We define a function generate_unique_email to create a placeholder email for records with invalid or missing email addresses.\n",
    "* Ensuring Numeric Data: We convert the Price and StockQuantity fields in products_df to numeric values. Any non-numeric data is replaced with a default value (0.0 for prices, 0 for stock quantities).\n",
    "* Standardizing Dates: Dates in orders_df and payments_df are standardized to a consistent format (YYYY-MM-DD) and any invalid dates are replaced with a default placeholder date (1970-01-01).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb88b67",
   "metadata": {},
   "source": [
    "# Phase 3: Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70a45fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all records from Authors, Books, Books_genres, Customers, Genres, Inventory, Order_items, Orders, Payments and Warehouses tables\n",
    "tables_to_clear = ['order_items', 'orders', 'payments', 'inventory', 'customers', 'books_genres', 'genres', 'books', 'authors', 'warehouses']\n",
    "for table in tables_to_clear:\n",
    "    cursor.execute(f\"TRUNCATE TABLE {table}\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f09032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into Authors table\n",
    "author_id_mapping = {}\n",
    "for index, row in authors_df.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO authors (author_name, date_of_birth)\n",
    "        VALUES (%s, %s)\n",
    "    \"\"\", (row['author_name'], row['date_of_birth']))\n",
    "    \n",
    "    author_id_mapping[index] = cursor.lastrowid\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c28f295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into Books table\n",
    "book_id_mapping = {}\n",
    "for index, row in books_df.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO books (title, author_id, release_date, list_price, description)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "    \"\"\", (row['title'], row['author_id'], row['release_date'], row['list_price'], row['description']))\n",
    "\n",
    "    book_id_mapping[index] = cursor.lastrowid\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1b2b70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into Genres table\n",
    "genre_id_mapping = {}\n",
    "for index, row in genres_df.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO genres (genre)\n",
    "        VALUES (%s)\n",
    "    \"\"\", (row['genre']))\n",
    "    \n",
    "    genre_id_mapping[index] = cursor.lastrowid\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33fc859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into Books_Genres table\n",
    "book_genre_id_mapping = {}\n",
    "for index, row in book_genres_df.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO books_genres (book_id, genre_id)\n",
    "        VALUES (%s, %s)\n",
    "    \"\"\", (row['book_id'], row['genre_id']))\n",
    "    \n",
    "    book_genre_id_mapping[index] = cursor.lastrowid\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36e53b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into Customers table\n",
    "customer_id_mapping = {}\n",
    "for index, row in customers_df.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO customers (name, gender, date_of_birth, postal_code, country, region, city, street, house_no, email_address, registration_date)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\", (row['name'], row['gender'], row['dateofbirth'], row['postalcode'], row['country'], row['region'], row['city'], row['street'],\n",
    "          row['houseno'], row['emailaddress'], row['registrationdate']))\n",
    "    \n",
    "    customer_id_mapping[index] = cursor.lastrowid\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d49135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into Warehouses table\n",
    "warehouse_id_mapping = {}\n",
    "for index, row in warehouses_df.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO warehouses (name, location, country)\n",
    "        VALUES (%s, %s, %s)\n",
    "    \"\"\", (row['name'], row['location'], row['country']))\n",
    "    \n",
    "    warehouse_id_mapping[index] = cursor.lastrowid\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f2b09f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into Payments table\n",
    "payment_id_mapping = {}\n",
    "for index, row in payments_df.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO payments (method)\n",
    "        VALUES (%s)\n",
    "    \"\"\", (row['payment_type']))\n",
    "    \n",
    "    payment_id_mapping[index] = cursor.lastrowid\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72991052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import random\n",
    "\n",
    "# # Number of books (adjust based on your dataset)\n",
    "# num_books = 40\n",
    "\n",
    "# # Warehouse IDs (1 to 8)\n",
    "# warehouses = list(range(1, 9))\n",
    "\n",
    "# # Open file to write\n",
    "# with open('inventory2.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     # Write header\n",
    "#     writer.writerow(['book_id', 'warehouse_id', 'quantity'])\n",
    "    \n",
    "#     # Generate inventory data\n",
    "#     for book_id in range(1, num_books + 1):\n",
    "#         for warehouse_id in warehouses:\n",
    "#             quantity = random.randint(10, 40)\n",
    "#             writer.writerow([book_id, warehouse_id, quantity])\n",
    "\n",
    "# print(\"inventory.csv file generated with\", num_books * len(warehouses), \"rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac6fbf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into Inventory table\n",
    "inventory_id_mapping = {}\n",
    "for index, row in inventory_df.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO inventory (book_id, warehouse_id, quantity)\n",
    "        VALUES (%s, %s, %s)\n",
    "    \"\"\", (row['book_id'], row['warehouse_id'], row['quantity']))\n",
    "    \n",
    "    inventory_id_mapping[index] = cursor.lastrowid\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75bbe63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into Orders table\n",
    "order_id_mapping = {}\n",
    "for index, row in orders_df.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO orders (order_date, ship_date, customer_id, payment_id, total_items, total_amount)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\", (row['order_date'], row['ship_date'], row['customer_id'], row['payment_id'], row['total_stock'], row['total_amount']))\n",
    "    \n",
    "    order_id_mapping[index] = cursor.lastrowid\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab222b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(f\"TRUNCATE TABLE orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "475b62ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into Order items table\n",
    "cursor.execute(f\"TRUNCATE TABLE order_items\")\n",
    "order_item_id_mapping = {}\n",
    "for index, row in order_items_df.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO order_items (order_id, book_id, warehouse_id, order_quantity, unit_price, unit_price_discount)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\", (row['order_id'], row['book_id'], row['warehouse_id'], row['order_quantity'], row['unit_price'], row['unit_price_discount']))\n",
    "    \n",
    "    order_item_id_mapping[index] = cursor.lastrowid\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54a7960",
   "metadata": {},
   "source": [
    "## What’s Happening Here?\n",
    "* Clearing Existing Data: Before inserting new data, we delete all records from the target tables (Payments, Reviews, Orders, Users, and Products) to avoid conflicts and ensure we’re working with fresh data.\n",
    "* Inserting Data: We iterate through each DataFrame, row by row, and insert the data into the corresponding table in the MySQL database. The cursor.execute method is used to run SQL INSERT statements with the data from each row.\n",
    "* Mapping IDs: As we insert data, we map old IDs to new ones. For instance, the UserID in the Orders table is updated to match the new UserID in the Users table after insertion.\n",
    "* Filtering and Loading Reviews: We filter out any invalid reviews (e.g., those with missing ratings) before inserting them into the Reviews table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3d56d5",
   "metadata": {},
   "source": [
    "## Final Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afc66882-3ee3-4341-b4d2-35b913ad3de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Final Verification\n",
    "# def verify_table_count(table_name, expected_count):\n",
    "#     cursor.execute(f\"SELECT COUNT(*) FROM {table_name}\")\n",
    "#     count = cursor.fetchone()[0]\n",
    "#     if count == expected_count:\n",
    "#         print(f\"{table_name} verification passed: {count} records.\")\n",
    "#     else:\n",
    "#         print(f\"{table_name} verification failed: Expected {expected_count}, but found {count}.\")\n",
    "\n",
    "# # Verify Products table\n",
    "# verify_table_count('Products', len(products_df))\n",
    "\n",
    "# # Verify Users table\n",
    "# verify_table_count('Users', len(users_df))\n",
    "\n",
    "# # Verify Orders table\n",
    "# verify_table_count('Orders', len(orders_df))\n",
    "\n",
    "# # Verify Payments table\n",
    "# verify_table_count('Payments', len(payments_df))\n",
    "\n",
    "# # Verify Reviews table\n",
    "# verify_table_count('Reviews', len(reviews_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2e402e",
   "metadata": {},
   "source": [
    "## What’s Happening Here?\n",
    "* We define a verify_table_count function that checks the number of records in each table and compares it to the expected count from the DataFrames.\n",
    "* This ensures that all data has been correctly inserted into the database and that no records were missed.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
